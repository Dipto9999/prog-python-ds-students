{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming in Python for Data Science \n",
    "\n",
    "# Assignment 8: A Slice of NumPy and Advanced Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Use [NumPy](https://numpy.org/) to create ndarrays with `np.array()` and from functions such as `np.arrange()`, `np.linspace()` and `np.ones()`.\n",
    "- Describe the shape, dimension and size of an array.\n",
    "- Identify null values in a dataframe and manage them by removing them using [`.dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) or replacing them using [`.fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html).\n",
    "- Manipulate non-standard date/time formats into standard Pandas datetime using [`pd.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html).\n",
    "- Find, and replace text from a dataframe using verbs such as [`.replace()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html) and [`.contains()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html).  \n",
    "\n",
    "\n",
    "This assignment covers [Module 8](https://prog-learn.mds.ubc.ca/en/module8) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` and the `raise NotImplementedError # No Answer - remove if you provide an answer` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import test_assignment8 as t\n",
    "from hashlib import sha1\n",
    "import altair as alt\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Using NumPy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(a)** <br> {points: 1}  \n",
    "\n",
    "Create a slice from `arr` named `answer_1a` of the values `[1,5,9]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccb41cc6c4b9d2064caa428628f427c5",
     "grade": false,
     "grade_id": "cell-7b80f2b644a4757d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 9])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = np.arange(1, 11)\n",
    "answer_1a = np.array([arr[1-1], arr[5-1], arr[9-1]])\n",
    "display(answer_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfbb05c5094ee8e379fcb1036c7b57dc",
     "grade": true,
     "grade_id": "cell-233c610c3e325009",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1a(answer_1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(b)** <br> {points: 1}  \n",
    "\n",
    "Create a 2d array named `answer_1b` of shape (2,2) filled with value 3.4 using `np.full()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Return a new array of given shape and type, filled with `fill_value`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "shape : int or sequence of ints\n",
      "    Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "fill_value : scalar or array_like\n",
      "    Fill value.\n",
      "dtype : data-type, optional\n",
      "    The desired data-type for the array  The default, None, means\n",
      "     ``np.array(fill_value).dtype``.\n",
      "order : {'C', 'F'}, optional\n",
      "    Whether to store multidimensional data in C- or Fortran-contiguous\n",
      "    (row- or column-wise) order in memory.\n",
      "like : array_like\n",
      "    Reference object to allow the creation of arrays which are not\n",
      "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "    the ``__array_function__`` protocol, the result will be defined\n",
      "    by it. In this case, it ensures the creation of an array object\n",
      "    compatible with that passed in via this argument.\n",
      "\n",
      "    .. versionadded:: 1.20.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "out : ndarray\n",
      "    Array of `fill_value` with the given shape, dtype, and order.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "full_like : Return a new array with shape of input filled with value.\n",
      "empty : Return a new uninitialized array.\n",
      "ones : Return a new array setting values to one.\n",
      "zeros : Return a new array setting values to zero.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> np.full((2, 2), np.inf)\n",
      "array([[inf, inf],\n",
      "       [inf, inf]])\n",
      ">>> np.full((2, 2), 10)\n",
      "array([[10, 10],\n",
      "       [10, 10]])\n",
      "\n",
      ">>> np.full((2, 2), [1, 2])\n",
      "array([[1, 2],\n",
      "       [1, 2]])\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\muntakim\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\numpy\\core\\numeric.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?np.full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b33d6525a69d602dc138f7d5227a221a",
     "grade": false,
     "grade_id": "cell-cb7051f7b662526f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4, 3.4],\n",
       "       [3.4, 3.4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_1b = np.full(\n",
    "    shape = (2,2),\n",
    "    fill_value = 3.4\n",
    ")\n",
    "\n",
    "display(answer_1b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f04605997a99780f13c360d6e445c1b",
     "grade": true,
     "grade_id": "cell-03b999c84ddf04cf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1b(answer_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(c)** <br> {points: 1}  \n",
    "\n",
    "Create a 3d array named `answer_1c` of shape (2, 3, 4) using `np.ones()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca49b183ed72ade7f565188bfbd04777",
     "grade": false,
     "grade_id": "cell-d2f7a5586208696b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_1c = np.ones(\n",
    "    shape = (2, 3, 4)\n",
    ")\n",
    "display(answer_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5acaebc1aa9f7386c493367424cc40b6",
     "grade": true,
     "grade_id": "cell-ff05643a3d8c885d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1c(answer_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(d)** <br> {points: 2}  \n",
    "\n",
    "Which of the following arrays are two dimensional? \n",
    "\n",
    " `array_1 = np.array([1, 4, 5, 6])`\n",
    "\n",
    " `array_2 = np.array([[1, 4, 5, 6]])`\n",
    "\n",
    " `array_3 = np.array([[1], [4], [5], [6]])`\n",
    "\n",
    " `array_4 = np.array([[[1, 4]], [[5, 6]]])`\n",
    "\n",
    "Save all possible answers as strings within a list.      \n",
    "Remember you can chose from the following data types:  \n",
    "\n",
    "***Example:***    \n",
    "\n",
    "`answer1_d = ['array_1', 'array_2']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_1 = np.array([1, 4, 5, 6])\n",
    "array_2 = np.array([[1, 4, 5, 6]])\n",
    "array_3 = np.array([[1], [4], [5], [6]])\n",
    "array_4 = np.array([[[1, 4]], [[5, 6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1 Shape (4,)\n",
      "Array 2 Shape (1, 4)\n",
      "Array 3 Shape (4, 1)\n",
      "Array 4 Shape (2, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Array 1 Shape {array_1.shape}')\n",
    "print(f'Array 2 Shape {array_2.shape}')\n",
    "print(f'Array 3 Shape {array_3.shape}')\n",
    "print(f'Array 4 Shape {array_4.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9813f8724293765ef209d13705345e1",
     "grade": false,
     "grade_id": "cell-f50baa637608027f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer1_d = ['array_2', 'array_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10ad2f8d2c42a4d7082af108a78445a9",
     "grade": true,
     "grade_id": "cell-61580423e6ff000f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the function exists\n",
    "assert 'answer1_d' in globals(\n",
    "), \"Please make sure that your solution is named 'answer1_d'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DateTime Wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Chopped_(TV_series)\" target=\"_blank\">Chopped</a> is a cooking show aired in North America where 4 contestants must prepare a dish that incorporates unusual basket ingredients unknown to the contestants beforehand. The dishes are then presented to a panel of three celebrity chef judges where the contestant of the least liked dish is \"chopped\" from the competition. There are 3 rounds in the contest (\"Appetizer\", \"Entrée\", and \"Dessert\") and the winner of the final round is deemed the \"Chopped Champion\". \n",
    "\n",
    "[This Chopped open-source dataset](https://www.kaggle.com/jeffreybraun/chopped-10-years-of-episode-data) combines allows us to identify some insights into this popular TV series. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(a)** <br> {points: 1}  \n",
    "\n",
    "Load in the data, assigning the `air_date` column as  `Datetime64` dtype.     \n",
    "Save the dataframe as an object named `chopped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1becce16c2732855b7c5f415bddde9a",
     "grade": false,
     "grade_id": "cell-88f46c5a55749a6c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chopped = pd.read_csv(\n",
    "    'data/chopped.csv',\n",
    "    parse_dates = ['air_date']\n",
    ")\n",
    "\n",
    "display(chopped['air_date'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf2ae43e6249ae0a78ac808a4cfa4fd7",
     "grade": true,
     "grade_id": "cell-b7923cff39c4cd75",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2a(chopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(b)** <br> {points: 2}  \n",
    "\n",
    "Determine how long the show been airing for (in years) by looking at the earliest and latest air dates.\n",
    "\n",
    "Save the result as an object named `air_length_yrs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Row : 2009-01-13 00:00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Final Row : 2020-07-28 00:00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"First Row : {chopped.iloc[0]['air_date']}\")\n",
    "display(f\"Final Row : {chopped.iloc[-1]['air_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chopped.sort_values(by = 'air_date', ascending = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Row : 2009-01-13 00:00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Final Row : 2020-07-28 00:00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"First Row : {chopped.iloc[0]['air_date']}\")\n",
    "display(f\"Final Row : {chopped.iloc[-1]['air_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e0bab539b29d16e8362e4500156c254",
     "grade": false,
     "grade_id": "cell-35afcf11a98e882b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "air_length_yrs = (chopped.iloc[-1]['air_date'] - chopped.iloc[0]['air_date']).days\n",
    "days_per_year = 365.25 # This is the total number of days per year including 0.25 to account for the leap year.\n",
    "air_length_yrs/= days_per_year\n",
    "\n",
    "air_length_yrs = round(air_length_yrs, 2) # This will round your answer to 2 decimal places. Do not delete! \n",
    "display(air_length_yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22f5db9a60b2b98861bf87e2a27a1c42",
     "grade": true,
     "grade_id": "cell-aa1c0e1acc2be419",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the function exists\n",
    "assert 'air_length_yrs' in globals(\n",
    "), \"Please make sure that your solution is named 'air_length_yrs'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(c)** <br> {points: 1}  \n",
    "\n",
    "How many days are between each of the 569 episodes?  \n",
    "Save this as an object named `days_apart`. \n",
    "\n",
    "*Hints:* \n",
    "- You may need to use `.diff()` and `days_apart` should have 568 rows.        \n",
    "- Here you are measuring time between episodes. `diff()` produces a dataframe that have a `NaT` value for the first row since there is no episode before it to calculate an interval from. We need to remove this row. Although there are 569 episodes, the number of intervals *between* episodes is 568.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad5b4e474121926ea8fc3024a630f5a3",
     "grade": false,
     "grade_id": "cell-3f9dd8e88f540a44",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      7 days\n",
       "1      7 days\n",
       "2      7 days\n",
       "3      7 days\n",
       "4      7 days\n",
       "        ...  \n",
       "563    7 days\n",
       "564    7 days\n",
       "565    7 days\n",
       "566   14 days\n",
       "567    7 days\n",
       "Name: air_date, Length: 568, dtype: timedelta64[ns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "days_apart = chopped['air_date'].diff().dropna().reset_index().drop(columns = 'index').squeeze()\n",
    "display(days_apart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46dfea09fa2039983713bd05e66acf6f",
     "grade": true,
     "grade_id": "cell-3c041bdc6e09a568",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2c(days_apart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(d)** <br> {points: 1}  \n",
    "\n",
    "Of these inter-episode intervals, what fraction of them were not aired on a weekly basis? \n",
    "\n",
    "Save the result in an object named `irregular_aired_fraction`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b9a5edd57dd8bc176f9d40dc3132923",
     "grade": false,
     "grade_id": "cell-528e8ce3e2b59861",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477112676056338"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "irregular_aired_fraction = days_apart.where(days_apart != dt.timedelta(days = 7)).dropna().size/days_apart.size\n",
    "display(irregular_aired_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c0a21caa5be4b6c53b0ed9db4a0c628",
     "grade": true,
     "grade_id": "cell-ad928e9679b8f5a0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2d(irregular_aired_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(e)** <br> {points: 1}  \n",
    "\n",
    "Make a new dataframe named `chopped2` that contains an additional column named `weekday_aired` that specifies the day of the week that it was aired.\n",
    "\n",
    "*Hint: you'll need to used `dt.day_name()`* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Return the day names of the DateTimeIndex with specified locale.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "locale : str, optional\n",
      "    Locale determining the language in which to return the day name.\n",
      "    Default is English locale.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "Index\n",
      "    Index of day names.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> idx = pd.date_range(start='2018-01-01', freq='D', periods=3)\n",
      ">>> idx\n",
      "DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      ">>> idx.day_name()\n",
      "Index(['Monday', 'Tuesday', 'Wednesday'], dtype='object')\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\muntakim\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\accessor.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?pd.Series.dt.day_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea8befc1ce26a533b527a5bf8b82047c",
     "grade": false,
     "grade_id": "cell-69913dfd530de335",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>series_episode</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_notes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>judge1</th>\n",
       "      <th>judge2</th>\n",
       "      <th>judge3</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>...</th>\n",
       "      <th>dessert</th>\n",
       "      <th>contestant1</th>\n",
       "      <th>contestant1_info</th>\n",
       "      <th>contestant2</th>\n",
       "      <th>contestant2_info</th>\n",
       "      <th>contestant3</th>\n",
       "      <th>contestant3_info</th>\n",
       "      <th>contestant4</th>\n",
       "      <th>contestant4_info</th>\n",
       "      <th>weekday_aired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Octopus, Duck, Animal Crackers\"</td>\n",
       "      <td>This is the first episode with only three offi...</td>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>baby octopus, bok choy, oyster sauce, smoked ...</td>\n",
       "      <td>...</td>\n",
       "      <td>prunes, animal crackers, cream cheese</td>\n",
       "      <td>Summer Kriegshauser</td>\n",
       "      <td>Private Chef and Nutrition Coach  New York  NY</td>\n",
       "      <td>Perry Pollaci</td>\n",
       "      <td>Private Chef and Sous chef  Bar Blanc  New Yo...</td>\n",
       "      <td>Katie Rosenhouse</td>\n",
       "      <td>Pastry Chef  Olana Restaurant  New York  NY</td>\n",
       "      <td>Sandy Davis</td>\n",
       "      <td>Catering Chef  Showstoppers Catering at Union...</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Tofu, Blueberries, Oysters\"</td>\n",
       "      <td>This is the first of a few episodes with five ...</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>firm tofu, tomato paste, prosciutto</td>\n",
       "      <td>...</td>\n",
       "      <td>phyllo dough, gorgonzola cheese, pineapple ri...</td>\n",
       "      <td>Raymond Jackson</td>\n",
       "      <td>Private Caterer and Culinary Instructor  West...</td>\n",
       "      <td>Klaus Kronsteiner</td>\n",
       "      <td>Chef de cuisine  Liberty National Golf Course...</td>\n",
       "      <td>Christopher Jackson</td>\n",
       "      <td>Executive Chef and Owner  Ted and Honey  Broo...</td>\n",
       "      <td>Pippa Calland</td>\n",
       "      <td>Owner and Chef  Chef for Hire LLC  Newville  PA</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Avocado, Tahini, Bran Flakes\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-01-27</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>lump crab meat, dried shiitake mushrooms, pin...</td>\n",
       "      <td>...</td>\n",
       "      <td>brioche, cantaloupe, pecans, avocados</td>\n",
       "      <td>Margaritte Malfy</td>\n",
       "      <td>Executive Chef and Co-owner  La Palapa  New Y...</td>\n",
       "      <td>Rachelle Rodwell</td>\n",
       "      <td>Chef de cuisine  SoHo Grand Hotel  New York  NY</td>\n",
       "      <td>Chris Burke</td>\n",
       "      <td>Private Chef  New York  NY</td>\n",
       "      <td>Andre Marrero</td>\n",
       "      <td>Chef tournant  L’Atelier de Joël Robuchon  Ne...</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Banana, Collard Greens, Grits\"</td>\n",
       "      <td>In the appetizer round, Chef Chuboda refused t...</td>\n",
       "      <td>2009-02-03</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Amanda Freitag</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>ground beef, wonton wrappers, cream of mushro...</td>\n",
       "      <td>...</td>\n",
       "      <td>maple syrup, black plums, almond butter, waln...</td>\n",
       "      <td>Sean Chudoba</td>\n",
       "      <td>Executive Chef  Ayza Wine Bar  New York  NY</td>\n",
       "      <td>Kyle Shadix</td>\n",
       "      <td>Chef  Registered Dietician and Culinary Consu...</td>\n",
       "      <td>Luis Gonzales</td>\n",
       "      <td>Executive Chef  Knickerbocker Bar &amp; Grill  Ne...</td>\n",
       "      <td>Einat Admony</td>\n",
       "      <td>Chef and Owner  Taïm  New York  NY</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>\"Yucca, Watermelon, Tortillas\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-02-10</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>watermelon, canned sardines, pepper jack chee...</td>\n",
       "      <td>...</td>\n",
       "      <td>flour tortillas, prosecco, Canadian bacon, ro...</td>\n",
       "      <td>John Keller</td>\n",
       "      <td>Personal Chef  New York  NY</td>\n",
       "      <td>Andrea Bergquist</td>\n",
       "      <td>Executive Chef  New York  NY</td>\n",
       "      <td>Ed Witt</td>\n",
       "      <td>Executive Chef / Wine Director  Bloomingdale ...</td>\n",
       "      <td>Josh Emett</td>\n",
       "      <td>Chef de cuisine  Gordon Ramsay at The London ...</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  season_episode  series_episode                      episode_name  \\\n",
       "0       1               1               1  \"Octopus, Duck, Animal Crackers\"   \n",
       "1       1               2               2      \"Tofu, Blueberries, Oysters\"   \n",
       "2       1               3               3    \"Avocado, Tahini, Bran Flakes\"   \n",
       "3       1               4               4   \"Banana, Collard Greens, Grits\"   \n",
       "4       1               5               5    \"Yucca, Watermelon, Tortillas\"   \n",
       "\n",
       "                                       episode_notes   air_date  \\\n",
       "0  This is the first episode with only three offi... 2009-01-13   \n",
       "1  This is the first of a few episodes with five ... 2009-01-20   \n",
       "2                                                NaN 2009-01-27   \n",
       "3  In the appetizer round, Chef Chuboda refused t... 2009-02-03   \n",
       "4                                                NaN 2009-02-10   \n",
       "\n",
       "              judge1              judge2             judge3  \\\n",
       "0        Marc Murphy  Alex Guarnaschelli      Aarón Sánchez   \n",
       "1      Aarón Sánchez  Alex Guarnaschelli        Marc Murphy   \n",
       "2      Aarón Sánchez  Alex Guarnaschelli        Marc Murphy   \n",
       "3       Scott Conant      Amanda Freitag  Geoffrey Zakarian   \n",
       "4  Geoffrey Zakarian  Alex Guarnaschelli        Marc Murphy   \n",
       "\n",
       "                                           appetizer  ...  \\\n",
       "0   baby octopus, bok choy, oyster sauce, smoked ...  ...   \n",
       "1               firm tofu, tomato paste, prosciutto   ...   \n",
       "2   lump crab meat, dried shiitake mushrooms, pin...  ...   \n",
       "3   ground beef, wonton wrappers, cream of mushro...  ...   \n",
       "4   watermelon, canned sardines, pepper jack chee...  ...   \n",
       "\n",
       "                                             dessert          contestant1  \\\n",
       "0              prunes, animal crackers, cream cheese  Summer Kriegshauser   \n",
       "1   phyllo dough, gorgonzola cheese, pineapple ri...      Raymond Jackson   \n",
       "2              brioche, cantaloupe, pecans, avocados     Margaritte Malfy   \n",
       "3   maple syrup, black plums, almond butter, waln...         Sean Chudoba   \n",
       "4   flour tortillas, prosecco, Canadian bacon, ro...          John Keller   \n",
       "\n",
       "                                    contestant1_info         contestant2  \\\n",
       "0    Private Chef and Nutrition Coach  New York  NY        Perry Pollaci   \n",
       "1   Private Caterer and Culinary Instructor  West...   Klaus Kronsteiner   \n",
       "2   Executive Chef and Co-owner  La Palapa  New Y...    Rachelle Rodwell   \n",
       "3       Executive Chef  Ayza Wine Bar  New York  NY          Kyle Shadix   \n",
       "4                       Personal Chef  New York  NY     Andrea Bergquist   \n",
       "\n",
       "                                    contestant2_info           contestant3  \\\n",
       "0   Private Chef and Sous chef  Bar Blanc  New Yo...      Katie Rosenhouse   \n",
       "1   Chef de cuisine  Liberty National Golf Course...   Christopher Jackson   \n",
       "2   Chef de cuisine  SoHo Grand Hotel  New York  NY            Chris Burke   \n",
       "3   Chef  Registered Dietician and Culinary Consu...         Luis Gonzales   \n",
       "4                      Executive Chef  New York  NY                Ed Witt   \n",
       "\n",
       "                                    contestant3_info     contestant4  \\\n",
       "0       Pastry Chef  Olana Restaurant  New York  NY      Sandy Davis   \n",
       "1   Executive Chef and Owner  Ted and Honey  Broo...   Pippa Calland   \n",
       "2                        Private Chef  New York  NY    Andre Marrero   \n",
       "3   Executive Chef  Knickerbocker Bar & Grill  Ne...    Einat Admony   \n",
       "4   Executive Chef / Wine Director  Bloomingdale ...      Josh Emett   \n",
       "\n",
       "                                    contestant4_info weekday_aired  \n",
       "0   Catering Chef  Showstoppers Catering at Union...       Tuesday  \n",
       "1   Owner and Chef  Chef for Hire LLC  Newville  PA        Tuesday  \n",
       "2   Chef tournant  L’Atelier de Joël Robuchon  Ne...       Tuesday  \n",
       "3                Chef and Owner  Taïm  New York  NY        Tuesday  \n",
       "4   Chef de cuisine  Gordon Ramsay at The London ...       Tuesday  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>series_episode</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_notes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>judge1</th>\n",
       "      <th>judge2</th>\n",
       "      <th>judge3</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>...</th>\n",
       "      <th>dessert</th>\n",
       "      <th>contestant1</th>\n",
       "      <th>contestant1_info</th>\n",
       "      <th>contestant2</th>\n",
       "      <th>contestant2_info</th>\n",
       "      <th>contestant3</th>\n",
       "      <th>contestant3_info</th>\n",
       "      <th>contestant4</th>\n",
       "      <th>contestant4_info</th>\n",
       "      <th>weekday_aired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>563</td>\n",
       "      <td>\"Terrine Cuisine\"</td>\n",
       "      <td>Chef Jose cut himself in the first round and c...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>Chris Santos</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Erik Ramirez</td>\n",
       "      <td>rabbit terrine, guanciale, spring garlic, bur...</td>\n",
       "      <td>...</td>\n",
       "      <td>feta ice cream, pears, blueberry ketchup, cho...</td>\n",
       "      <td>Jose Luis Chavez</td>\n",
       "      <td>Chef and Owner from New York  NY</td>\n",
       "      <td>Matt Greiner</td>\n",
       "      <td>Executive Chef from Raleigh  NC</td>\n",
       "      <td>Mimi Weissenborn</td>\n",
       "      <td>Executive Chef from Harlem  NY</td>\n",
       "      <td>Nemo Bolin</td>\n",
       "      <td>Chef and Owner from Providence  RI</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>564</td>\n",
       "      <td>\"Time and Turmoil\"</td>\n",
       "      <td>Chef Arden forgot an ingredient in the first r...</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>Amanda Freitag</td>\n",
       "      <td>Maneet Chauhan</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>hash brown patties, Manila clams, escarole, b...</td>\n",
       "      <td>...</td>\n",
       "      <td>boozy cranberry gelatin, cherry scones, necta...</td>\n",
       "      <td>Lindsay Smith-Rosales</td>\n",
       "      <td>Chef and Owner from Laguna Beach  CA</td>\n",
       "      <td>Arden Lewis</td>\n",
       "      <td>Executive Chef from New York  NY</td>\n",
       "      <td>Lina Zarcaro</td>\n",
       "      <td>Private Chef from Bradley Beach  NJ</td>\n",
       "      <td>Luca Annunziata</td>\n",
       "      <td>Executive Chef from Charlotte  NC</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>565</td>\n",
       "      <td>\"Jarring Jars\"</td>\n",
       "      <td>The guest judge in this episode was Chef Ray G...</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Ray Garcia</td>\n",
       "      <td>sea beans, dehydrated carrot sticks, egg coff...</td>\n",
       "      <td>...</td>\n",
       "      <td>guava, kefir, honeycomb, pickled pig lips</td>\n",
       "      <td>May Siricharoen</td>\n",
       "      <td>Executive Chef from Los Angeles  CA</td>\n",
       "      <td>Chris Day</td>\n",
       "      <td>Executive Sous Chef from Boston  MA</td>\n",
       "      <td>Patrick McKee</td>\n",
       "      <td>Executive Chef from Portland  OR</td>\n",
       "      <td>Phillip Esteban</td>\n",
       "      <td>Research &amp; Development Chef from San Diego  CA</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>566</td>\n",
       "      <td>\"Cauliflower Power\"</td>\n",
       "      <td>In this unofficially vegetarian themed episode...</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>Maneet Chauhan</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>Esther Choi</td>\n",
       "      <td>cauliflower avocado toast, cauliflower rice, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>cauliflower oatmeal, halo-halo fruit mix, red...</td>\n",
       "      <td>Manjit Manohar</td>\n",
       "      <td>Executive Sous Chef from New York  NY</td>\n",
       "      <td>Edy Massih</td>\n",
       "      <td>Private Chef and Caterer from Brooklyn  NY</td>\n",
       "      <td>Megan Marlow</td>\n",
       "      <td>Executive Chef and Owner from Los Angeles  CA</td>\n",
       "      <td>Kei Ohdera</td>\n",
       "      <td>Chef and Owner from Portland  OR</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>567</td>\n",
       "      <td>\"Quail Without Fail\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>Chris Santos</td>\n",
       "      <td>Maneet Chauhan</td>\n",
       "      <td>Geoffrey Zacharian</td>\n",
       "      <td>gopchang, ghost pepper aioli, nopales, hominy</td>\n",
       "      <td>...</td>\n",
       "      <td>chicken salt, syrniki, passion fruit, cajeta</td>\n",
       "      <td>Bryant Kryck</td>\n",
       "      <td>Executive Chef from Portland  OR</td>\n",
       "      <td>Caroline Hough</td>\n",
       "      <td>Chef de Cuisine from Philadelphia  PA</td>\n",
       "      <td>Marco Maestoso</td>\n",
       "      <td>Chef and Owner from San Diego  CA</td>\n",
       "      <td>Calin Sauvron</td>\n",
       "      <td>Executive Chef from Bethel  CT</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  season_episode  series_episode          episode_name  \\\n",
       "564      45               9             563     \"Terrine Cuisine\"   \n",
       "565      45              10             564    \"Time and Turmoil\"   \n",
       "566      45              11             565        \"Jarring Jars\"   \n",
       "567      45              12             566   \"Cauliflower Power\"   \n",
       "568      45              13             567  \"Quail Without Fail\"   \n",
       "\n",
       "                                         episode_notes   air_date  \\\n",
       "564  Chef Jose cut himself in the first round and c... 2020-06-23   \n",
       "565  Chef Arden forgot an ingredient in the first r... 2020-06-30   \n",
       "566  The guest judge in this episode was Chef Ray G... 2020-07-07   \n",
       "567  In this unofficially vegetarian themed episode... 2020-07-21   \n",
       "568                                                NaN 2020-07-28   \n",
       "\n",
       "             judge1             judge2              judge3  \\\n",
       "564    Chris Santos       Scott Conant        Erik Ramirez   \n",
       "565  Amanda Freitag     Maneet Chauhan        Scott Conant   \n",
       "566    Scott Conant  Geoffrey Zakarian          Ray Garcia   \n",
       "567  Maneet Chauhan        Marc Murphy         Esther Choi   \n",
       "568    Chris Santos     Maneet Chauhan  Geoffrey Zacharian   \n",
       "\n",
       "                                             appetizer  ...  \\\n",
       "564   rabbit terrine, guanciale, spring garlic, bur...  ...   \n",
       "565   hash brown patties, Manila clams, escarole, b...  ...   \n",
       "566   sea beans, dehydrated carrot sticks, egg coff...  ...   \n",
       "567   cauliflower avocado toast, cauliflower rice, ...  ...   \n",
       "568     gopchang, ghost pepper aioli, nopales, hominy   ...   \n",
       "\n",
       "                                               dessert            contestant1  \\\n",
       "564   feta ice cream, pears, blueberry ketchup, cho...       Jose Luis Chavez   \n",
       "565   boozy cranberry gelatin, cherry scones, necta...  Lindsay Smith-Rosales   \n",
       "566          guava, kefir, honeycomb, pickled pig lips        May Siricharoen   \n",
       "567   cauliflower oatmeal, halo-halo fruit mix, red...         Manjit Manohar   \n",
       "568       chicken salt, syrniki, passion fruit, cajeta           Bryant Kryck   \n",
       "\n",
       "                            contestant1_info      contestant2  \\\n",
       "564        Chef and Owner from New York  NY      Matt Greiner   \n",
       "565    Chef and Owner from Laguna Beach  CA       Arden Lewis   \n",
       "566     Executive Chef from Los Angeles  CA         Chris Day   \n",
       "567   Executive Sous Chef from New York  NY        Edy Massih   \n",
       "568        Executive Chef from Portland  OR    Caroline Hough   \n",
       "\n",
       "                                 contestant2_info        contestant3  \\\n",
       "564              Executive Chef from Raleigh  NC    Mimi Weissenborn   \n",
       "565             Executive Chef from New York  NY        Lina Zarcaro   \n",
       "566          Executive Sous Chef from Boston  MA       Patrick McKee   \n",
       "567   Private Chef and Caterer from Brooklyn  NY        Megan Marlow   \n",
       "568        Chef de Cuisine from Philadelphia  PA      Marco Maestoso   \n",
       "\n",
       "                                    contestant3_info       contestant4  \\\n",
       "564                  Executive Chef from Harlem  NY         Nemo Bolin   \n",
       "565             Private Chef from Bradley Beach  NJ    Luca Annunziata   \n",
       "566                Executive Chef from Portland  OR    Phillip Esteban   \n",
       "567   Executive Chef and Owner from Los Angeles  CA         Kei Ohdera   \n",
       "568               Chef and Owner from San Diego  CA      Calin Sauvron   \n",
       "\n",
       "                                     contestant4_info weekday_aired  \n",
       "564               Chef and Owner from Providence  RI        Tuesday  \n",
       "565                Executive Chef from Charlotte  NC        Tuesday  \n",
       "566   Research & Development Chef from San Diego  CA        Tuesday  \n",
       "567                 Chef and Owner from Portland  OR        Tuesday  \n",
       "568                   Executive Chef from Bethel  CT        Tuesday  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chopped2 = chopped.assign(weekday_aired = lambda x : x['air_date'].dt.day_name())\n",
    "display(chopped2.head())\n",
    "display(chopped2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ec3cf8bfeccab6275971d32f2ce07b6",
     "grade": true,
     "grade_id": "cell-68f5f90cd65b7862",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2e(chopped2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(f)** <br> {points: 1}  \n",
    "\n",
    "Most Chopped episodes are aired on a `Tuesday`. How many were not? \n",
    "Save this value in an object name `irregular_airdays`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602739e2caf4049ec18b3f138706056e",
     "grade": false,
     "grade_id": "cell-e71011e93164f761",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "irregular_airdays = len(chopped2.query(f'weekday_aired != \"Tuesday\"'))\n",
    "display(irregular_airdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a79b3f036e74b5c64c7b1f388e6be63",
     "grade": true,
     "grade_id": "cell-eb44cb00fd6dc68d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2f(irregular_airdays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(g)** <br> {points: 2}  \n",
    "\n",
    "How many of the 45 chopped seasons had a perfectly consistent schedule with each episode being released exactly on a weekly basis?\n",
    "Save this value in an object name `num_perfect_season`.\n",
    "\n",
    "*Hint:*\n",
    "\n",
    "* You may find some of the skills you used in 2(c) and 2(d) helpful here. \n",
    "* To loop over all the groups in a groupby object you can use the syntax `for name, group in data.groupby(['grouping_column']):`.\n",
    "* For a season to have a consistence airing schedule, both the max and min days between episodes would equal 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Difference between two datetime values.\n",
      "\n",
      "timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
      "\n",
      "All arguments are optional and default to 0.\n",
      "Arguments may be integers or floats, and may be positive or negative.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\muntakim\\appdata\\local\\programs\\python\\python310\\lib\\datetime.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     _Timedelta\n"
     ]
    }
   ],
   "source": [
    "?dt.timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regular_aired = chopped[['season', 'air_date']].sort_values(['season', 'air_date'], ascending = True)\n",
    "regular_aired = regular_aired.assign(days_apart = lambda x : x['air_date'].diff()).dropna()\n",
    "\n",
    "num_perfect_season = 0\n",
    "for i, season in regular_aired.groupby(['season']) :\n",
    "    days_apart = season.iloc[1:]['days_apart'].drop_duplicates().to_list()\n",
    "    if (len(days_apart) == 1) and (days_apart[0] == dt.timedelta(days = 7)) :\n",
    "        num_perfect_season += 1\n",
    "display(num_perfect_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0ceb99d0357185ce435b5907706198a",
     "grade": true,
     "grade_id": "cell-efe0bfc5d6967ba7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2g(num_perfect_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning a dataframe with Strings and Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** <br> {points: 8}  \n",
    "\n",
    "Now that you have learned about string operations and an entry level of regular expressions, let's see you apply your skills to a real dataset. \n",
    "\n",
    "In this exercise, you will start with the dirty version of the `Gapminder` dataset that we've seen before. By \"dirty\" we mean there are some inconsistencies and irregularities in the dataset as one would more typically find with real world data.  Your task is to write a function named `clean_gapminder` that takes in this dataset as an argument, and returns a cleaned up dataframe. The goal of this exercise is to use Python code to clean up the `dirty_gapminder` to the point that it's identical to `clean_gapminder`. \n",
    "\n",
    "Note: in the real world you wouldn't have a `clean_gapminder` reference to compare to!\n",
    "\n",
    "Things you might want to do to clean up `dirty_gapminder`:\n",
    "\n",
    "1. We recommend first writing code that cleans this dataset and then moving it all into a function after. \n",
    "1. If there is missing data (NaNs or empty strings) fill it in with sensible values.\n",
    "1. Check that all values match those in `clean_gapminder` (e.g., check capitalization, spelling, grammar, etc).\n",
    "1. There may be entries that appear to have the exact same spelling and capitalization in both the dirty and clean gapminder datasets, but still don't match... Extra whitespace is often a frustrating (and invisible) problem when wrangling text data. You can use `print('**' + x + '**')` to identify any strings with whitespace and `Series.str.strip()` to trim unwanted whitespace around a string. \n",
    "1. When you are ready, test that your dirty dataframe matches the clean gapminder data using `df.equals()`.\n",
    "1. Since you are writing a function named `cleaned_gapminder`, our autograding tests will grade that your function contains certain code and returns the expected output.\n",
    "\n",
    "Hint: We've provided a unit test for you to compare the two dataframes after wranging. However, during your wrangling you can check the equality of individual elements in two dataframes using `df.eq()`. If your dataframes are `df1` and `df2`, you can check which rows are not equal using `df1[(~df2.eq(df1)).any(axis=1)]` (You've seen something of this nature in Module 3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1952</td>\n",
       "      <td>8425333.0</td>\n",
       "      <td>28.801</td>\n",
       "      <td>779.445314</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>9240934.0</td>\n",
       "      <td>30.332</td>\n",
       "      <td>820.853030</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962</td>\n",
       "      <td>10267083.0</td>\n",
       "      <td>31.997</td>\n",
       "      <td>853.100710</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1967</td>\n",
       "      <td>11537966.0</td>\n",
       "      <td>34.020</td>\n",
       "      <td>836.197138</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972</td>\n",
       "      <td>13079460.0</td>\n",
       "      <td>36.088</td>\n",
       "      <td>739.981106</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         pop  lifeExp   gdpPercap continent      country\n",
       "0  1952   8425333.0   28.801  779.445314      Asia  Afghanistan\n",
       "1  1957   9240934.0   30.332  820.853030      Asia  Afghanistan\n",
       "2  1962  10267083.0   31.997  853.100710      Asia  Afghanistan\n",
       "3  1967  11537966.0   34.020  836.197138      Asia  Afghanistan\n",
       "4  1972  13079460.0   36.088  739.981106      Asia  Afghanistan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>continent</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1987</td>\n",
       "      <td>9216418.0</td>\n",
       "      <td>62.351</td>\n",
       "      <td>706.157306</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>1992</td>\n",
       "      <td>10704340.0</td>\n",
       "      <td>60.377</td>\n",
       "      <td>693.420786</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>1997</td>\n",
       "      <td>11404948.0</td>\n",
       "      <td>46.809</td>\n",
       "      <td>792.449960</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>2002</td>\n",
       "      <td>11926563.0</td>\n",
       "      <td>39.989</td>\n",
       "      <td>672.038623</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>2007</td>\n",
       "      <td>12311143.0</td>\n",
       "      <td>43.487</td>\n",
       "      <td>469.709298</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year         pop  lifeExp   gdpPercap continent   country\n",
       "1699  1987   9216418.0   62.351  706.157306    Africa  Zimbabwe\n",
       "1700  1992  10704340.0   60.377  693.420786    Africa  Zimbabwe\n",
       "1701  1997  11404948.0   46.809  792.449960    Africa  Zimbabwe\n",
       "1702  2002  11926563.0   39.989  672.038623    Africa  Zimbabwe\n",
       "1703  2007  12311143.0   43.487  469.709298    Africa  Zimbabwe"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirty = pd.read_csv('data/dirty_gapminder.csv')\n",
    "display(dirty.head())\n",
    "display(dirty.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>8425333.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>28.801</td>\n",
       "      <td>779.445314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1957</td>\n",
       "      <td>9240934.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>30.332</td>\n",
       "      <td>820.853030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1962</td>\n",
       "      <td>10267083.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>31.997</td>\n",
       "      <td>853.100710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1967</td>\n",
       "      <td>11537966.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>34.020</td>\n",
       "      <td>836.197138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1972</td>\n",
       "      <td>13079460.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>36.088</td>\n",
       "      <td>739.981106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year         pop continent  lifeExp   gdpPercap\n",
       "0  Afghanistan  1952   8425333.0      Asia   28.801  779.445314\n",
       "1  Afghanistan  1957   9240934.0      Asia   30.332  820.853030\n",
       "2  Afghanistan  1962  10267083.0      Asia   31.997  853.100710\n",
       "3  Afghanistan  1967  11537966.0      Asia   34.020  836.197138\n",
       "4  Afghanistan  1972  13079460.0      Asia   36.088  739.981106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1987</td>\n",
       "      <td>9216418.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>62.351</td>\n",
       "      <td>706.157306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1992</td>\n",
       "      <td>10704340.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>60.377</td>\n",
       "      <td>693.420786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1997</td>\n",
       "      <td>11404948.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>46.809</td>\n",
       "      <td>792.449960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2002</td>\n",
       "      <td>11926563.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>39.989</td>\n",
       "      <td>672.038623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2007</td>\n",
       "      <td>12311143.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>43.487</td>\n",
       "      <td>469.709298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year         pop continent  lifeExp   gdpPercap\n",
       "1699  Zimbabwe  1987   9216418.0    Africa   62.351  706.157306\n",
       "1700  Zimbabwe  1992  10704340.0    Africa   60.377  693.420786\n",
       "1701  Zimbabwe  1997  11404948.0    Africa   46.809  792.449960\n",
       "1702  Zimbabwe  2002  11926563.0    Africa   39.989  672.038623\n",
       "1703  Zimbabwe  2007  12311143.0    Africa   43.487  469.709298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean = pd.read_csv('data/clean_gapminder.csv')\n",
    "display(clean.head())\n",
    "display(clean.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows that there are 28 rows in total that are not equal between the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 6)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty[(~clean.eq(dirty)).any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53e698634889e4f5542e926c99751f37",
     "grade": false,
     "grade_id": "cell-91958e9802fb7ae9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1992</td>\n",
       "      <td>10315702.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>72.400</td>\n",
       "      <td>14297.021220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1997</td>\n",
       "      <td>10300707.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>74.010</td>\n",
       "      <td>16048.514240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>10256295.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>75.510</td>\n",
       "      <td>17596.210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2007</td>\n",
       "      <td>10228744.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>76.486</td>\n",
       "      <td>22833.308510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>1972</td>\n",
       "      <td>23007669.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>45.989</td>\n",
       "      <td>904.896068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              country  year         pop continent  lifeExp  \\\n",
       "403                    Czech Republic  1992  10315702.0    Europe   72.400   \n",
       "404                    Czech Republic  1997  10300707.0    Europe   74.010   \n",
       "405                    Czech Republic  2002  10256295.0    Europe   75.510   \n",
       "406                    Czech Republic  2007  10228744.0    Europe   76.486   \n",
       "407  Democratic Republic of the Congo  1972  23007669.0    Africa   45.989   \n",
       "\n",
       "        gdpPercap  \n",
       "403  14297.021220  \n",
       "404  16048.514240  \n",
       "405  17596.210220  \n",
       "406  22833.308510  \n",
       "407    904.896068  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1987</td>\n",
       "      <td>10311597.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>71.580</td>\n",
       "      <td>16310.44340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1992</td>\n",
       "      <td>10315702.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>72.400</td>\n",
       "      <td>14297.02122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1997</td>\n",
       "      <td>10300707.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>74.010</td>\n",
       "      <td>16048.51424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2002</td>\n",
       "      <td>10256295.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>75.510</td>\n",
       "      <td>17596.21022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>2007</td>\n",
       "      <td>10228744.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>76.486</td>\n",
       "      <td>22833.30851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country  year         pop continent  lifeExp    gdpPercap\n",
       "403  Czech Republic  1987  10311597.0    Europe   71.580  16310.44340\n",
       "404  Czech Republic  1992  10315702.0    Europe   72.400  14297.02122\n",
       "405  Czech Republic  1997  10300707.0    Europe   74.010  16048.51424\n",
       "406  Czech Republic  2002  10256295.0    Europe   75.510  17596.21022\n",
       "407  Czech Republic  2007  10228744.0    Europe   76.486  22833.30851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cleaned_gapminder(dirty_df):\n",
    "    '''\n",
    "    Clean the GapMinder DataFrame to be the same as the Cleaned DataFrame.\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    dirty_df : pandas.core.frame.DataFrame\n",
    "        The dataframe to clean     \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.core.frame.DataFrame\n",
    "        The cleaned GapMinder DataFrame \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>>\n",
    "\n",
    "    '''\n",
    "    dirty_df = dirty_df[[\n",
    "        'country',\n",
    "        'year',\n",
    "        'pop',\n",
    "        'continent',\n",
    "        'lifeExp',\n",
    "        'gdpPercap',\n",
    "    ]].replace(\n",
    "        to_replace = 'china',\n",
    "        value = 'China',\n",
    "    ).replace(\n",
    "        to_replace = 'Central african republic',\n",
    "        value = 'Central African Republic',\n",
    "    ).dropna(how = 'all').drop_duplicates()\n",
    "\n",
    "    # Order DataFrame is Ascending Order By Country, Year.\n",
    "    dirty_df = dirty_df.sort_values(\n",
    "        ['country', 'year']\n",
    "    ).reset_index().drop(columns = ['index'])\n",
    "    \n",
    "    # Assign Continent to Americas for Canada.\n",
    "    dirty_df.loc[dirty_df[dirty_df['country'] == 'Canada'].index, 'continent'] = 'Americas'\n",
    "    \n",
    "    # Remove Leading/Trailing Whitespaces\n",
    "    dirty_df['country'] = dirty_df['country'].str.strip()\n",
    "    dirty_df['continent'] = dirty_df['continent'].str.strip()\n",
    "\n",
    "    return dirty_df\n",
    "\n",
    "cleaned_data = cleaned_gapminder(dirty)\n",
    "\n",
    "# display(cleaned_data.head())\n",
    "# display(cleaned_data.tail())\n",
    "\n",
    "# display(cleaned_data.query(f'country == \"Czech Republic\"'))\n",
    "# display(clean.query(f'country == \"Czech Republic\"'))\n",
    "\n",
    "df_1 = cleaned_data[(~clean.eq(cleaned_data)).any(axis=1)]\n",
    "df_2 = clean[(~cleaned_data.eq(clean)).any(axis=1)]\n",
    "\n",
    "# for col in df_1.columns :\n",
    "#     if not (df_1.iloc[0][col] == df_2.iloc[0][col]) :\n",
    "#         print(f'DF1 {col} : {df_1.iloc[0][col]}')\n",
    "#         print(f'DF2 {col} : {df_2.iloc[0][col]}')\n",
    "\n",
    "display(df_1.tail())\n",
    "display(df_2.tail())\n",
    "\n",
    "# assert cleaned_data.equals(clean), \"Dataframes are not the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f5eb62647bcce88be97757fb7a626de",
     "grade": true,
     "grade_id": "cell-4d822c98c340d7d7",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Make sure you are replacing the missing values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\My_Files\\School\\School_Work\\Engineering_Bachelors\\2022\\KeyCapabilities_DataScience\\prog-python-ds-students\\release\\assignment8\\assignment8.ipynb Cell 59\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/My_Files/School/School_Work/Engineering_Bachelors/2022/KeyCapabilities_DataScience/prog-python-ds-students/release/assignment8/assignment8.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m t\u001b[39m.\u001b[39;49mtest_3(cleaned_gapminder,dirty,clean)\n",
      "File \u001b[1;32mc:\\My_Files\\School\\School_Work\\Engineering_Bachelors\\2022\\KeyCapabilities_DataScience\\prog-python-ds-students\\release\\assignment8\\test_assignment8.py:71\u001b[0m, in \u001b[0;36mtest_3\u001b[1;34m(answer, dirty, clean)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m answer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mYour function does not exist. Have you passed in the correct function?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m str_fun \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetsource(answer)\n\u001b[1;32m---> 71\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfillna\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m str_fun, \u001b[39m\"\u001b[39m\u001b[39mMake sure you are replacing the missing values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstr.strip()\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m str_fun, \u001b[39m\"\u001b[39m\u001b[39mMake sure you are removing unwanted whitespaces.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39massign\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m str_fun, \u001b[39m\"\u001b[39m\u001b[39mMake sure that when fixing columns, you are assigning it a column name.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Make sure you are replacing the missing values."
     ]
    }
   ],
   "source": [
    "t.test_3(cleaned_gapminder,dirty,clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You did it! You got to the end of all 8 assignments in Programming in Python for Data Science. We are all very proud of you here and are excited to see you translate everything you've learned into a final project! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- Gapminder Dataset - [Gapminder](https://www.gapminder.org/data/)\n",
    "- UBC's original STAT545 - [Stat545 by Jenny Bryan](https://stat545.com/)\n",
    "- MDS DSCI 523 - Data Wrangling course - [MDS's GitHub website](https://ubc-mds.github.io/) \n",
    "- Chopped Dataset - [Kaggle](https://www.kaggle.com/jeffreybraun/chopped-10-years-of-episode-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Debriefing\n",
    "\n",
    "If this video is not showing up below, click on the cell and click the ▶ button in the toolbar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('PCBPzCFQwHs', width=854, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "98e2f3d2dd73e88fe48fb6a6de651cd001c0152773ca91edda490fb6b3cd2dfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
