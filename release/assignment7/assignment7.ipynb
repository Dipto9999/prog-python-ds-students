{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming in Python for Data Science \n",
    "\n",
    "# Assignment 7: Importing Files and the Coding Style Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Describe what Python libraries are, as well as explain when and why they are useful.\n",
    "- Identify where code can be improved concerning variable names, magic numbers, comments and whitespace.\n",
    "- Write code that is human readable and follows the black style guide.\n",
    "- Import files from other directories.\n",
    "- Use [`pytest`](https://docs.pytest.org/en/stable/) to check a function's tests.\n",
    "- When running [`pytest`](https://docs.pytest.org/en/stable/), explain how pytest finds the associated test functions.\n",
    "- Explain how the Python debugger can help rectify your code.\n",
    "\n",
    "This assignment covers [Module 7](https://prog-learn.mds.ubc.ca/en/module7) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` and the `raise NotImplementedError # No Answer - remove if you provide an answer` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "import test_assignment7 as t\n",
    "from hashlib import sha1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Importing libraries   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(a)** <br> {points: 1}  \n",
    "\n",
    "Import the `pandas` library and name it `pd` in the worksheet environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e7a239b989f8065dc779eac5c0db120",
     "grade": false,
     "grade_id": "cell-33212a70ac92beea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f685f2f8a2ce8ecc6e254989ff98820",
     "grade": true,
     "grade_id": "cell-932eba7b75fc58b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1a(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(b)** <br> {points: 1}  \n",
    "\n",
    "Import the Altair library into the worksheet enviroment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36271cc448c00e70899b7d28563bf9bb",
     "grade": false,
     "grade_id": "cell-2fb5b8e075bbd416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61befda99759541fa776cd5b609d4863",
     "grade": true,
     "grade_id": "cell-eca513c226d7f7f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(c)** <br> {points: 1}  \n",
    "\n",
    "From the `numpy` library, only import the `arange()` function using the keywork `from`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e04a06ede5f30fe883b4bc81409da5a4",
     "grade": false,
     "grade_id": "cell-e99cf81fa9d22012",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a8ebfc54a36aa71ca44dd915c08591d",
     "grade": true,
     "grade_id": "cell-cf28d80fe773f520",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with other files  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(a)** <br> {points: 1}  \n",
    "\n",
    "Load in the `chopped.csv` file from the data folder and save it as an object named `chopped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d5320b231dfcaedd4e56b3582c60daa",
     "grade": false,
     "grade_id": "cell-6134753661931f24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped = pd.read_csv('data/chopped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec65ca40ff824242d121b0d208b4070e",
     "grade": true,
     "grade_id": "cell-746bfa633c7af0a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2a(chopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(b)** <br> {points: 1}  \n",
    "\n",
    "Import the function `sample_dataframe()` (that we created in Assignment 6) from `sampling.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3390bf4c0478081f9033c3610846add3",
     "grade": false,
     "grade_id": "cell-a60b50fcb75443d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sampling import sample_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cd337866dc4a04621d25f3fbe0ebce2",
     "grade": true,
     "grade_id": "cell-635d330803423f4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(c)** <br> {points: 2}  \n",
    "\n",
    "To refresh yourself on what the function `sample_dataframe()` does, inspect the function docstring.  \n",
    "\n",
    "Which of the following is the correct way to inspect the docstring of the function `sample_dataframe()`?     \n",
    "*Hint: Try it out yourself*\n",
    "\n",
    "A) `?sample.sample_dataframe`\n",
    "\n",
    "B) `?sample.sample_dataframe()` \n",
    "\n",
    "C) `?sample_dataframe`\n",
    "\n",
    "D) `?sample_dataframe()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer2_c`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37ea0df60619ac283eb5e272a0aa8c4",
     "grade": false,
     "grade_id": "cell-7fcb41f86f7ea257",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_c = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f518f3ab0ad13f24297344e661616fb",
     "grade": true,
     "grade_id": "cell-35291c2eeae630fd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0msample_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrouping_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Given a dataframe, return a smaller sample of the dataframe\n",
      "sampling N rows from each specified group\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : pandas.core.frame.DataFrame\n",
      "    The dataframe to sample from\n",
      "grouping_col : str\n",
      "    The column to filter our condition on\n",
      "N : int, optional\n",
      "    The number of rows to sample from each group (The default value is 1\n",
      "    which implies a single observation)\n",
      "    \n",
      "Returns\n",
      "-------\n",
      "pandas.core.frame.DataFrame\n",
      "    The new sampled dataframe\n",
      "    \n",
      "Examples\n",
      "--------\n",
      ">>> sample_dataframe(pokemon, 'legendary'])\n",
      "    name     deck_no  attack  defense  type    gen  legendary\n",
      "411 Burmy     412     29        45      bug     4      0\n",
      "640 Tornadus  641     100       80      flying  5      1\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\my_files\\school\\school_work\\engineering_bachelors\\2022\\keycapabilities_datascience\\prog-python-ds-students\\release\\assignment7\\sampling.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?sample_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(d)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter is optional?       \n",
    "Answer the parameter name as a `str` in the object `answer2_d`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d1ef9c2fe2ed9b7c9d97ecc9146b943",
     "grade": false,
     "grade_id": "cell-e8920e5152e7e308",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_d = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b33e02e909283893e74a4671d385864b",
     "grade": true,
     "grade_id": "cell-5821de7729f52862",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2d(answer2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(e)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter accepts data types of `str`?      \n",
    "\n",
    "Answer the parameter name as a `str` in the object `answer2_e`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e24962220dde0237ba12efbd484be1",
     "grade": false,
     "grade_id": "cell-e676311b515dde12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_e = 'grouping_col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b425c2b493cee2b74194928aeff2432",
     "grade": true,
     "grade_id": "cell-3fd7084db8d73672",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2e(answer2_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(f)** <br> {points: 1}  \n",
    "\n",
    "Sample two rows from each season from the `chopped` dataframe using your function `sample_dataframe`.     \n",
    "\n",
    "Save this in an object named `chopped_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>series_episode</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_notes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>judge1</th>\n",
       "      <th>judge2</th>\n",
       "      <th>judge3</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>entree</th>\n",
       "      <th>dessert</th>\n",
       "      <th>contestant1</th>\n",
       "      <th>contestant1_info</th>\n",
       "      <th>contestant2</th>\n",
       "      <th>contestant2_info</th>\n",
       "      <th>contestant3</th>\n",
       "      <th>contestant3_info</th>\n",
       "      <th>contestant4</th>\n",
       "      <th>contestant4_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Octopus, Duck, Animal Crackers\"</td>\n",
       "      <td>This is the first episode with only three offi...</td>\n",
       "      <td>January 13, 2009</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>baby octopus, bok choy, oyster sauce, smoked ...</td>\n",
       "      <td>duck breast, green onions, ginger, honey</td>\n",
       "      <td>prunes, animal crackers, cream cheese</td>\n",
       "      <td>Summer Kriegshauser</td>\n",
       "      <td>Private Chef and Nutrition Coach  New York  NY</td>\n",
       "      <td>Perry Pollaci</td>\n",
       "      <td>Private Chef and Sous chef  Bar Blanc  New Yo...</td>\n",
       "      <td>Katie Rosenhouse</td>\n",
       "      <td>Pastry Chef  Olana Restaurant  New York  NY</td>\n",
       "      <td>Sandy Davis</td>\n",
       "      <td>Catering Chef  Showstoppers Catering at Union...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Tofu, Blueberries, Oysters\"</td>\n",
       "      <td>This is the first of a few episodes with five ...</td>\n",
       "      <td>January 20, 2009</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>firm tofu, tomato paste, prosciutto</td>\n",
       "      <td>daikon, pork loin, Napa cabbage, Thai chiles,...</td>\n",
       "      <td>phyllo dough, gorgonzola cheese, pineapple ri...</td>\n",
       "      <td>Raymond Jackson</td>\n",
       "      <td>Private Caterer and Culinary Instructor  West...</td>\n",
       "      <td>Klaus Kronsteiner</td>\n",
       "      <td>Chef de cuisine  Liberty National Golf Course...</td>\n",
       "      <td>Christopher Jackson</td>\n",
       "      <td>Executive Chef and Owner  Ted and Honey  Broo...</td>\n",
       "      <td>Pippa Calland</td>\n",
       "      <td>Owner and Chef  Chef for Hire LLC  Newville  PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Avocado, Tahini, Bran Flakes\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>January 27, 2009</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>lump crab meat, dried shiitake mushrooms, pin...</td>\n",
       "      <td>ground beef, cannellini beans, tahini paste, ...</td>\n",
       "      <td>brioche, cantaloupe, pecans, avocados</td>\n",
       "      <td>Margaritte Malfy</td>\n",
       "      <td>Executive Chef and Co-owner  La Palapa  New Y...</td>\n",
       "      <td>Rachelle Rodwell</td>\n",
       "      <td>Chef de cuisine  SoHo Grand Hotel  New York  NY</td>\n",
       "      <td>Chris Burke</td>\n",
       "      <td>Private Chef  New York  NY</td>\n",
       "      <td>Andre Marrero</td>\n",
       "      <td>Chef tournant  L’Atelier de Joël Robuchon  Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Banana, Collard Greens, Grits\"</td>\n",
       "      <td>In the appetizer round, Chef Chuboda refused t...</td>\n",
       "      <td>February 3, 2009</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Amanda Freitag</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>ground beef, wonton wrappers, cream of mushro...</td>\n",
       "      <td>scallops, collard greens, anchovies, sour cream</td>\n",
       "      <td>maple syrup, black plums, almond butter, waln...</td>\n",
       "      <td>Sean Chudoba</td>\n",
       "      <td>Executive Chef  Ayza Wine Bar  New York  NY</td>\n",
       "      <td>Kyle Shadix</td>\n",
       "      <td>Chef  Registered Dietician and Culinary Consu...</td>\n",
       "      <td>Luis Gonzales</td>\n",
       "      <td>Executive Chef  Knickerbocker Bar &amp; Grill  Ne...</td>\n",
       "      <td>Einat Admony</td>\n",
       "      <td>Chef and Owner  Taïm  New York  NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>\"Yucca, Watermelon, Tortillas\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>February 10, 2009</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>watermelon, canned sardines, pepper jack chee...</td>\n",
       "      <td>beef shoulder, yucca, raisins, ancho chiles, ...</td>\n",
       "      <td>flour tortillas, prosecco, Canadian bacon, ro...</td>\n",
       "      <td>John Keller</td>\n",
       "      <td>Personal Chef  New York  NY</td>\n",
       "      <td>Andrea Bergquist</td>\n",
       "      <td>Executive Chef  New York  NY</td>\n",
       "      <td>Ed Witt</td>\n",
       "      <td>Executive Chef / Wine Director  Bloomingdale ...</td>\n",
       "      <td>Josh Emett</td>\n",
       "      <td>Chef de cuisine  Gordon Ramsay at The London ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  season_episode  series_episode                      episode_name  \\\n",
       "0       1               1               1  \"Octopus, Duck, Animal Crackers\"   \n",
       "1       1               2               2      \"Tofu, Blueberries, Oysters\"   \n",
       "2       1               3               3    \"Avocado, Tahini, Bran Flakes\"   \n",
       "3       1               4               4   \"Banana, Collard Greens, Grits\"   \n",
       "4       1               5               5    \"Yucca, Watermelon, Tortillas\"   \n",
       "\n",
       "                                       episode_notes           air_date  \\\n",
       "0  This is the first episode with only three offi...   January 13, 2009   \n",
       "1  This is the first of a few episodes with five ...   January 20, 2009   \n",
       "2                                                NaN   January 27, 2009   \n",
       "3  In the appetizer round, Chef Chuboda refused t...   February 3, 2009   \n",
       "4                                                NaN  February 10, 2009   \n",
       "\n",
       "              judge1              judge2             judge3  \\\n",
       "0        Marc Murphy  Alex Guarnaschelli      Aarón Sánchez   \n",
       "1      Aarón Sánchez  Alex Guarnaschelli        Marc Murphy   \n",
       "2      Aarón Sánchez  Alex Guarnaschelli        Marc Murphy   \n",
       "3       Scott Conant      Amanda Freitag  Geoffrey Zakarian   \n",
       "4  Geoffrey Zakarian  Alex Guarnaschelli        Marc Murphy   \n",
       "\n",
       "                                           appetizer  \\\n",
       "0   baby octopus, bok choy, oyster sauce, smoked ...   \n",
       "1               firm tofu, tomato paste, prosciutto    \n",
       "2   lump crab meat, dried shiitake mushrooms, pin...   \n",
       "3   ground beef, wonton wrappers, cream of mushro...   \n",
       "4   watermelon, canned sardines, pepper jack chee...   \n",
       "\n",
       "                                              entree  \\\n",
       "0          duck breast, green onions, ginger, honey    \n",
       "1   daikon, pork loin, Napa cabbage, Thai chiles,...   \n",
       "2   ground beef, cannellini beans, tahini paste, ...   \n",
       "3   scallops, collard greens, anchovies, sour cream    \n",
       "4   beef shoulder, yucca, raisins, ancho chiles, ...   \n",
       "\n",
       "                                             dessert          contestant1  \\\n",
       "0              prunes, animal crackers, cream cheese  Summer Kriegshauser   \n",
       "1   phyllo dough, gorgonzola cheese, pineapple ri...      Raymond Jackson   \n",
       "2              brioche, cantaloupe, pecans, avocados     Margaritte Malfy   \n",
       "3   maple syrup, black plums, almond butter, waln...         Sean Chudoba   \n",
       "4   flour tortillas, prosecco, Canadian bacon, ro...          John Keller   \n",
       "\n",
       "                                    contestant1_info         contestant2  \\\n",
       "0    Private Chef and Nutrition Coach  New York  NY        Perry Pollaci   \n",
       "1   Private Caterer and Culinary Instructor  West...   Klaus Kronsteiner   \n",
       "2   Executive Chef and Co-owner  La Palapa  New Y...    Rachelle Rodwell   \n",
       "3       Executive Chef  Ayza Wine Bar  New York  NY          Kyle Shadix   \n",
       "4                       Personal Chef  New York  NY     Andrea Bergquist   \n",
       "\n",
       "                                    contestant2_info           contestant3  \\\n",
       "0   Private Chef and Sous chef  Bar Blanc  New Yo...      Katie Rosenhouse   \n",
       "1   Chef de cuisine  Liberty National Golf Course...   Christopher Jackson   \n",
       "2   Chef de cuisine  SoHo Grand Hotel  New York  NY            Chris Burke   \n",
       "3   Chef  Registered Dietician and Culinary Consu...         Luis Gonzales   \n",
       "4                      Executive Chef  New York  NY                Ed Witt   \n",
       "\n",
       "                                    contestant3_info     contestant4  \\\n",
       "0       Pastry Chef  Olana Restaurant  New York  NY      Sandy Davis   \n",
       "1   Executive Chef and Owner  Ted and Honey  Broo...   Pippa Calland   \n",
       "2                        Private Chef  New York  NY    Andre Marrero   \n",
       "3   Executive Chef  Knickerbocker Bar & Grill  Ne...    Einat Admony   \n",
       "4   Executive Chef / Wine Director  Bloomingdale ...      Josh Emett   \n",
       "\n",
       "                                    contestant4_info  \n",
       "0   Catering Chef  Showstoppers Catering at Union...  \n",
       "1   Owner and Chef  Chef for Hire LLC  Newville  PA   \n",
       "2   Chef tournant  L’Atelier de Joël Robuchon  Ne...  \n",
       "3                Chef and Owner  Taïm  New York  NY   \n",
       "4   Chef de cuisine  Gordon Ramsay at The London ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(chopped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "882ac872c1be42d6674b60036e238c2c",
     "grade": false,
     "grade_id": "cell-6299480a9da3c466",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped_sample = sample_dataframe(chopped, 'season', N = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>series_episode</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_notes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>judge1</th>\n",
       "      <th>judge2</th>\n",
       "      <th>judge3</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>entree</th>\n",
       "      <th>dessert</th>\n",
       "      <th>contestant1</th>\n",
       "      <th>contestant1_info</th>\n",
       "      <th>contestant2</th>\n",
       "      <th>contestant2_info</th>\n",
       "      <th>contestant3</th>\n",
       "      <th>contestant3_info</th>\n",
       "      <th>contestant4</th>\n",
       "      <th>contestant4_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>\"Quail, Arctic Char, Beer\"</td>\n",
       "      <td>In the appetizer Melinda did not get her quail...</td>\n",
       "      <td>February 24, 2009</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Amanda Freita</td>\n",
       "      <td>endive, frozen peas, quail, red seedless grapes</td>\n",
       "      <td>watercress, tamarind paste, creamed corn, Arc...</td>\n",
       "      <td>pitted dates, frozen pie crust, caramel candy...</td>\n",
       "      <td>Melinda Dorn</td>\n",
       "      <td>Sous chef and Instructor  New York  NY</td>\n",
       "      <td>Ralph Battista Jr.</td>\n",
       "      <td>Executive Chef  Butterfield 8  New York  NY</td>\n",
       "      <td>Lior Lev Sercarz</td>\n",
       "      <td>Chef and Entrepreneur  La Boîte à Biscuits an...</td>\n",
       "      <td>Abe Lopez</td>\n",
       "      <td>Chef de cuisine  Pacifico  Center Valley  PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>\"Jumbo Shrimp, Pepperoncini, Cereal\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>March 24, 2009</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Amanda Freita</td>\n",
       "      <td>peanut butter, Granny Smith apples, jumbo shr...</td>\n",
       "      <td>kielbasa, pepperoncini, fingerling potatoes, ...</td>\n",
       "      <td>marshmallow spread, chocolate puff cereal, se...</td>\n",
       "      <td>Alina Eisenhauer</td>\n",
       "      <td>Pastry Chef  Sweet  Woodstock  CT</td>\n",
       "      <td>Todd Miller</td>\n",
       "      <td>Executive Chef  STK  New York  NY</td>\n",
       "      <td>Michael Giletto</td>\n",
       "      <td>Executive Chef  Cherry Valley Country Club  S...</td>\n",
       "      <td>Jackie Lee</td>\n",
       "      <td>Private Chef  New York  NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>\"Chopped Champions Event, Round One: The Ultim...</td>\n",
       "      <td>This is the first \"Chopped Champions\" event, f...</td>\n",
       "      <td>September 8, 2009</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>crayfish, red seedless grapes, fiddlehead ferns</td>\n",
       "      <td>quail, guava nectar, udon noodles, dinosaur k...</td>\n",
       "      <td>baby kiwi, Israeli couscous, rice paper, saffron</td>\n",
       "      <td>Michael Carrino</td>\n",
       "      <td>Chef and Owner  Restaurant Passionné  Montcla...</td>\n",
       "      <td>Sandy Davis</td>\n",
       "      <td>Catering Chef  Union Theological Seminary  Ne...</td>\n",
       "      <td>Natalia Machado</td>\n",
       "      <td>Junior Executive Chef  Industria Argentina  N...</td>\n",
       "      <td>James Briscione</td>\n",
       "      <td>Chef Instructor  Institute of Culinary Educat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>\"Floundering Around\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>June 30, 2009</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Amanda Freitag</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>beef shoulder, fish sauce, canned pumpkin</td>\n",
       "      <td>flounder, yellow plantains, baby bok choy, mi...</td>\n",
       "      <td>tomatillos, crème fraîche, plain donuts</td>\n",
       "      <td>Massimo Felici</td>\n",
       "      <td>Executive Chef  Ristorante DeGrezia  New York...</td>\n",
       "      <td>Christine Campbell</td>\n",
       "      <td>Butcher and Private Chef  Long Island  NY</td>\n",
       "      <td>Julio Lazzarini</td>\n",
       "      <td>Executive Chef and Owner  Orillas Tapas Bar a...</td>\n",
       "      <td>Marc Spooner</td>\n",
       "      <td>Production Chef  Great Performances Catering ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season  season_episode  series_episode  \\\n",
       "6        1               7               7   \n",
       "10       1              11              11   \n",
       "22       2              10              23   \n",
       "16       2               4              17   \n",
       "\n",
       "                                         episode_name  \\\n",
       "6                          \"Quail, Arctic Char, Beer\"   \n",
       "10               \"Jumbo Shrimp, Pepperoncini, Cereal\"   \n",
       "22  \"Chopped Champions Event, Round One: The Ultim...   \n",
       "16                               \"Floundering Around\"   \n",
       "\n",
       "                                        episode_notes           air_date  \\\n",
       "6   In the appetizer Melinda did not get her quail...  February 24, 2009   \n",
       "10                                                NaN     March 24, 2009   \n",
       "22  This is the first \"Chopped Champions\" event, f...  September 8, 2009   \n",
       "16                                                NaN      June 30, 2009   \n",
       "\n",
       "               judge1              judge2         judge3  \\\n",
       "6        Scott Conant  Alex Guarnaschelli  Amanda Freita   \n",
       "10  Geoffrey Zakarian  Alex Guarnaschelli  Amanda Freita   \n",
       "22  Geoffrey Zakarian  Alex Guarnaschelli    Marc Murphy   \n",
       "16       Scott Conant      Amanda Freitag  Aarón Sánchez   \n",
       "\n",
       "                                            appetizer  \\\n",
       "6    endive, frozen peas, quail, red seedless grapes    \n",
       "10   peanut butter, Granny Smith apples, jumbo shr...   \n",
       "22   crayfish, red seedless grapes, fiddlehead ferns    \n",
       "16         beef shoulder, fish sauce, canned pumpkin    \n",
       "\n",
       "                                               entree  \\\n",
       "6    watercress, tamarind paste, creamed corn, Arc...   \n",
       "10   kielbasa, pepperoncini, fingerling potatoes, ...   \n",
       "22   quail, guava nectar, udon noodles, dinosaur k...   \n",
       "16   flounder, yellow plantains, baby bok choy, mi...   \n",
       "\n",
       "                                              dessert       contestant1  \\\n",
       "6    pitted dates, frozen pie crust, caramel candy...      Melinda Dorn   \n",
       "10   marshmallow spread, chocolate puff cereal, se...  Alina Eisenhauer   \n",
       "22   baby kiwi, Israeli couscous, rice paper, saffron   Michael Carrino   \n",
       "16            tomatillos, crème fraîche, plain donuts    Massimo Felici   \n",
       "\n",
       "                                     contestant1_info          contestant2  \\\n",
       "6             Sous chef and Instructor  New York  NY    Ralph Battista Jr.   \n",
       "10                 Pastry Chef  Sweet  Woodstock  CT           Todd Miller   \n",
       "22   Chef and Owner  Restaurant Passionné  Montcla...          Sandy Davis   \n",
       "16   Executive Chef  Ristorante DeGrezia  New York...   Christine Campbell   \n",
       "\n",
       "                                     contestant2_info        contestant3  \\\n",
       "6        Executive Chef  Butterfield 8  New York  NY    Lior Lev Sercarz   \n",
       "10                 Executive Chef  STK  New York  NY     Michael Giletto   \n",
       "22   Catering Chef  Union Theological Seminary  Ne...    Natalia Machado   \n",
       "16         Butcher and Private Chef  Long Island  NY     Julio Lazzarini   \n",
       "\n",
       "                                     contestant3_info       contestant4  \\\n",
       "6    Chef and Entrepreneur  La Boîte à Biscuits an...         Abe Lopez   \n",
       "10   Executive Chef  Cherry Valley Country Club  S...        Jackie Lee   \n",
       "22   Junior Executive Chef  Industria Argentina  N...   James Briscione   \n",
       "16   Executive Chef and Owner  Orillas Tapas Bar a...      Marc Spooner   \n",
       "\n",
       "                                     contestant4_info  \n",
       "6       Chef de cuisine  Pacifico  Center Valley  PA   \n",
       "10                        Private Chef  New York  NY   \n",
       "22   Chef Instructor  Institute of Culinary Educat...  \n",
       "16   Production Chef  Great Performances Catering ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(chopped_sample.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ec1de9cca0165ef824e2d7bf3b5ac1",
     "grade": true,
     "grade_id": "cell-a3352eba01015292",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2f(chopped_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Pytest\n",
    "\n",
    "We have provided you with another file called `test_sampling.py` which contains multiple functions that test if our `sample_dataframe()` function is working properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(a)** <br> {points: 1}  \n",
    "\n",
    "The tests for `sample_dataframe()` are located in a different file than the function which means we will need to import the function from our `sampling.py` file at the top of `test_sampling.py`. \n",
    "\n",
    "Open `test_sampling.py` and on line 2, write code to import the `sample_dataframe()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cade35fe5e7e6d5bb01615bec546eaa",
     "grade": true,
     "grade_id": "cell-ae85375476286d96",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a179132ad8eb5bbe5f4881b9e1cf29f",
     "grade": false,
     "grade_id": "cell-6b432fa592bfb361",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3(b)** <br>\n",
    "\n",
    "We are going to do things a little differently then in the lesson here. \n",
    "Using `pytest` in a jupyter notebook, we can check if all the tests in `test_sampling.py` pass using the code `!pytest test_sampling.py` in a code cell. \n",
    "\n",
    "\n",
    "Try it out in the cell below and answer the following multiple choice questions regarding the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.10.4, pytest-7.2.0, pluggy-1.0.0\n",
      "rootdir: c:\\My_Files\\School\\School_Work\\Engineering_Bachelors\\2022\\KeyCapabilities_DataScience\\prog-python-ds-students\\release\\assignment7\n",
      "collected 6 items\n",
      "\n",
      "test_sampling.py .....F                                                  [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "_______________________________ test_sd_cherry ________________________________\n",
      "\n",
      "    def test_sd_cherry():\n",
      "        raw = {'id': [1873, 4913, 4801, 4540, 3581,\n",
      "                       4534, 1934, 4944, 1983, 1266],\n",
      "               'name': ['English Oak', 'Higan Cherry', 'Willow Oak',\n",
      "                        'Yoshino Cherry', 'Red Oak', 'Kindred Spirit Oak',\n",
      "                        'Garry Oak', 'Accolade Cherry', 'Snow Goose Cherry',\n",
      "                        'Evergreen Oak'],\n",
      "                'neighbourhood': ['Sunset','West end','Kitsilano', 'Sunset',\n",
      "                                  'Arbutus-ridge','Arbutus-ridge', 'Kitsilano',\n",
      "                                  'West end','Kitsilano', 'Arbutus-ridge'],\n",
      "                'type': ['Oak', 'Cherry', 'Oak', 'Cherry', 'Oak',\n",
      "                         'Oak', 'Oak', 'Cherry', 'Cherry', 'Oak'],\n",
      "                'diameter': [9.0, 27.0, 3.0, 22.0, 3.0,\n",
      "                             6.5, 12.0, 18.0, 8.5, 23.0]}\n",
      "        helper_data = pd.DataFrame.from_dict(raw)\n",
      "    \n",
      "        sampler = sample_dataframe(helper_data, 'type', 1)\n",
      "    \n",
      "        # Tests that there are only 1 row of type \"Cherry\"\n",
      ">       assert sampler[sampler['type'] == 'Cherry'].shape[0] == 3, \"The dataframe should only have 1 row of type 'cherry'\"\n",
      "E       AssertionError: The dataframe should only have 1 row of type 'cherry'\n",
      "E       assert 1 == 3\n",
      "\n",
      "test_sampling.py:132: AssertionError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED test_sampling.py::test_sd_cherry - AssertionError: The dataframe shoul...\n",
      "========================= 1 failed, 5 passed in 2.14s =========================\n"
     ]
    }
   ],
   "source": [
    "!pytest test_sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-i)** <br> {points: 1}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` passed?      \n",
    "*Assign the correct answer to an object called `tests_passed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "547fbada2f64cffe0d00e10fbe452d9a",
     "grade": false,
     "grade_id": "cell-fb3fd2b5482fdc05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_passed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b1813b96d691c1eaf9f317d381a525",
     "grade": true,
     "grade_id": "cell-c687047bada4fe95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3bi(tests_passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-ii)** <br> {points: 2}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` failed?      \n",
    "*Assign the correct answer to an object called `tests_failed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a651b9fbb2e7b2a5b7300f40a4241b3f",
     "grade": false,
     "grade_id": "cell-1202fc67d62b1792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_failed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b81476073bd44de4e8817f9093fb0d",
     "grade": true,
     "grade_id": "cell-abcdd5212ce8810c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-iii)** <br> {points: 1}  \n",
    "\n",
    "Name a test that did not pass.   \n",
    "*Assign the correct answer to an object called `failed_name`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18a537e1b9d742949bb3e75ecaa94a9",
     "grade": false,
     "grade_id": "cell-67209bf44bc4b370",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "failed_name = 'test_sd_cherry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0480cd9b22932ceeef90d6c2fb046aa5",
     "grade": true,
     "grade_id": "cell-3d2823a898a6289a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3biii(failed_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Black and Flake8 Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a)** <br>\n",
    "\n",
    "Run Flake8 on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling.py:4:43: E251 unexpected spaces around keyword / parameter equals\n",
      "sampling.py:4:45: E251 unexpected spaces around keyword / parameter equals\n",
      "sampling.py:8:1: W293 blank line contains whitespace\n",
      "sampling.py:18:1: W293 blank line contains whitespace\n",
      "sampling.py:23:1: W293 blank line contains whitespace\n",
      "sampling.py:31:1: W293 blank line contains whitespace\n",
      "sampling.py:33:1: W293 blank line contains whitespace\n",
      "sampling.py:35:1: W293 blank line contains whitespace\n",
      "sampling.py:36:35: W291 trailing whitespace\n",
      "sampling.py:37:25: E222 multiple spaces after operator\n",
      "sampling.py:39:1: W293 blank line contains whitespace\n",
      "sampling.py:41:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-i)** <br> {points: 1}  \n",
    "\n",
    "How many formatting issues did flake8 recognize in the `sampling.py` file?      \n",
    "*Assign the correct answer to an object called `answer4_ai`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d4970e87ebc89bbab5933e526bc9d56",
     "grade": false,
     "grade_id": "cell-27db9cfd0445f2ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_ai = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9cedde3d5ecbc3f9cff73e87bc888b",
     "grade": true,
     "grade_id": "cell-da78b4046f2a5291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4ai(answer4_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-ii)** <br> {points: 1}  \n",
    "\n",
    "How many `W291 trailing whitespace` issues are there? (We will talk a little bit about trailing and leading white space in Module 8)       \n",
    "*Assign the correct answer to an object called `answer4_aii`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a12ea403bfdb2232c6d38b8c1b077c5",
     "grade": false,
     "grade_id": "cell-4380df8c2f16c985",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aii = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69531d3d00c1ce4dbdac5fb7d33de02e",
     "grade": true,
     "grade_id": "cell-ab23a0ce59a092f1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4aii(answer4_aii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-iii)** <br> {points: 1}  \n",
    "\n",
    "\n",
    "Which of the following is the formatting issue that occurs on line 36?     \n",
    "\n",
    "\n",
    "A) `E222 multiple spaces after operator`\n",
    "\n",
    "B) `W293 blank line contains whitespace`\n",
    "\n",
    "C) `W291 trailing whitespace`\n",
    "\n",
    "D) `E251 unexpected spaces around keyword / parameter equals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_aiii`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8ba94996c89f41c55e0462426fde910",
     "grade": false,
     "grade_id": "cell-4cdb5bce57b584a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aiii = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e8d3aab045252b408d7476ca95207e2",
     "grade": true,
     "grade_id": "cell-7775bd41eaf54724",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4aiii(answer4_aiii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(b)**  {points: 1}  \n",
    "\n",
    "Run `black` on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All done! ✨ 🍰 ✨\n",
      "1 file left unchanged.\n"
     ]
    }
   ],
   "source": [
    "!black sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which code would you use in a Jupyter code cell to run Black?\n",
    "\n",
    "A) `black sampling.py`\n",
    "\n",
    "B) `!black sampling.py` \n",
    "\n",
    "C) `sampling.black()`\n",
    "\n",
    "D) `black.sampling()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_b`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84c9e855c345eac9d7fd09bd3f7f8c1f",
     "grade": false,
     "grade_id": "cell-10e4f5655e22c244",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_b = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76e0feef20e3e846229cb069767abe38",
     "grade": true,
     "grade_id": "cell-c9348b9faa589abf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4b(answer4_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(c)** <br> {points: 2}  \n",
    "\n",
    "Now that we have reformatted our `sampling.py` file, let's rerun flake8 just as we did before as see how many of our formatting issues have been fixed and answer the question below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many formatting issues are we left with after re-runing flake8 after formatting `sampling.py` using the `black` style guide?\n",
    "\n",
    "*Assign the correct answer to an object called `answer4_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bee54132eb4c6c8c098d8c36a9eabec",
     "grade": false,
     "grade_id": "cell-a94532cb877f86ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602952b54c4dc96a00ec19e3e1b64280",
     "grade": true,
     "grade_id": "cell-b9a92e7037aad0c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Style Guide - Comments and Variable Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(a)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is most fitting for an object that contains a list of column names from a dataframe named `metals`? \n",
    "\n",
    "A) `metal_columns`\n",
    "\n",
    "B) `columnsfrommetaldataframe`\n",
    "\n",
    "C) `list`\n",
    "\n",
    "D) `c_metals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_a`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea99287d09106ebc9636ea5fdb831838",
     "grade": false,
     "grade_id": "cell-f50baa637608027f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_a = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f4cacdab2a71d36acc7317f216f4a80",
     "grade": true,
     "grade_id": "cell-141b5df587a3cc3e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5a(answer5_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(b)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is the best fitting for object containing a dataframe containing different lightbulb types?\n",
    "\n",
    "A) `LIGHTBULBS`\n",
    "\n",
    "B) `dataframe_where_lightbulbs_data_stored`\n",
    "\n",
    "C) `data`\n",
    "\n",
    "D) `lightbulb_df` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_b`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efffe815faf74591e38eb4b46312af57",
     "grade": false,
     "grade_id": "cell-1ac2beeec7f1258d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_b = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2d999013dd895239cbf204bb401bb5f",
     "grade": true,
     "grade_id": "cell-5a33f1e90db1379f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5b(answer5_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(c)** <br> {points: 2}  \n",
    "\n",
    "Which of the following is NOT a reasonable comment to include in your code?\n",
    "\n",
    "A) `# Keep this line of code in, or the function will break mysteriously`\n",
    "\n",
    "B) `# Rename columns to shorter column names`\n",
    "\n",
    "C) `# This assigns all the values greater than 100 a value of 100.`\n",
    "\n",
    "D) `# TODO: Fix this next part so it's more readable and doesn't include magic numbers` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b780f05c3efad8ea5202822858169d",
     "grade": false,
     "grade_id": "cell-58ce14551039cefd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_c = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc374f8eae271b873f35ee34826fc662",
     "grade": true,
     "grade_id": "cell-67d88876daa123c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(d)** <br> {points: 2}  \n",
    "\n",
    "Below is a function that plots a histogram of a specified quantitative column.\n",
    "We want you to identify the 4 poorly designed elements within this function, and rewrite/rename them to something that is more appropriate. \n",
    "\n",
    "Copy and paste the function into the cell that follows it and then make your desired changes.\n",
    "\n",
    "*Hint: The function name does not need to be changed* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "def column_histogram(data, column_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    Given a dataframe, this function creates a histogram\n",
    "    of the values from a specified column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        The dataframe to filter\n",
    "    column_name : str\n",
    "        The column values to plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    altair.vegalite.v4.api.Chart \n",
    "        the plotted histogram\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> column_histogram(chopped, \"season\")\n",
    "    altair.vegalite.v4.api.Chart \n",
    "    \"\"\"\n",
    "    \n",
    "    # This checks if the data variable is of type pd.dataframe\n",
    "    if not isinstance(data, pd.DataFrame): \n",
    "        raise TypeError(\"The data argument is not of type DataFrame\")   \n",
    "    \n",
    "    # This area is reserved for an exception which checks the column dtype of column_name, it could be useful\n",
    "    \n",
    "    cs = column_name + \":Q\"\n",
    "    \n",
    "    # This makes a histogram and plots the values of column_name frequency \n",
    "    histogram_plot_of_column_name = alt.Chart(data).mark_bar().encode(\n",
    "                                        alt.X( cs, bin=True),\n",
    "                                              y='count()',\n",
    "                                    )\n",
    "    \n",
    "    # This function now returns a histogram \n",
    "    return histogram_plot_of_column_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_histogram:0:1: E902 FileNotFoundError: [Errno 2] No such file or directory: 'column_histogram'\n"
     ]
    }
   ],
   "source": [
    "!flake8 column_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79d4f1778c613d7ac02986673ef33e5d",
     "grade": false,
     "grade_id": "cell-4e57ff3c843e88ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "raise NotImplementedError # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87ea3309c00598248532b21c9aec546",
     "grade": true,
     "grade_id": "cell-c8c1a1322f269763",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "t.test_5d(column_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- UBC's original STAT545 - [Stat545 by Jenny Bryan](https://stat545.com/)\n",
    "- MDS DSCI 523 - Data Wrangling course - [MDS's GitHub website](hhttps://ubc-mds.github.io/) \n",
    "- Chopped Dataset - [Kaggle](https://www.kaggle.com/jeffreybraun/chopped-10-years-of-episode-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Debriefing\n",
    "\n",
    "If this video is not showing up below, click on the cell and click the ▶ button in the toolbar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('hBGFNWtYoYw', width=854, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "98e2f3d2dd73e88fe48fb6a6de651cd001c0152773ca91edda490fb6b3cd2dfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
